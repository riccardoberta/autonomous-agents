{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi\n",
    "\n",
    "The [Taxi problem](https://gymnasium.farama.org/environments/toy_text/taxi/) involves navigating passengers in a grid world, picking them up and dropping them off at one of four locations (Red, Green, Yellow and Blue) in a 5x5 grid world. The taxi starts off at a random square and the passenger at one of the designated locations. The goal is move the taxi to the passenger’s location, pick up the passenger, move to the passenger’s desired destination, and drop off the passenger. Once the passenger is dropped off, the episode ends.\n",
    "\n",
    "<img src=\"./taxi.png\" width=\"200\">\n",
    "\n",
    "There is six possible actions. The agent can move to the four cardinal directions (south, north, east or west) and two other possible actions which are the pick-up or the drop-off:\n",
    "\n",
    "- 0: Move south (down)\n",
    "- 1: Move north (up)\n",
    "- 2: Move east (right)\n",
    "- 3: Move west (left)\n",
    "- 4: Pickup passenger\n",
    "- 5: Drop off passenger\n",
    "\n",
    "The state is described by the taxi location on the grid (a row and a column number between 0 and 4), a location to drop-off the passenger from four choices, and the passenger which can be in one of the four locations or inside the taxi, in total 500 discrete states. An observation is returned as an int that encodes the corresponding state, calculated by: \n",
    "((taxi_row * 5 + taxi_col) * 5 + passenger_location) * 4 + destination\n",
    "\n",
    "The player receives positive rewards for successfully dropping-off the passenger at the correct location. Negative rewards for incorrect attempts to pick-up/drop-off passenger and for each step where another reward is not received."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Import the 'Taxi-v3' grid word from Gymnasium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# You can get the environment from Gymnasium in the same way we got 'Frozen Lake’; \n",
    "# in order to visually plot the environment you can import it \n",
    "# using render_mode=\"rgb_array\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Create a random policy as a baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# You have to create a function that get in input a state and provide a random action\n",
    "# (in the range [0;5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Show the policy in action by rendering the environment several times after different decisions from the random policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# You have to use a while loop in order to provide the current state to \n",
    "# the policy and then make a step in the environment using the action \n",
    "# provided by the policy. \n",
    "# Try to create a function (to be called \"show_policy\") \n",
    "# to be reused with other policies later.\n",
    "# Hints: env.render() provides you an array representing \n",
    "# an image of the environment; plt.imshow() can be used to visualize \n",
    "# the image on the screen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Write a brute-force function in order to evaluate the probability of success and the average return obtained by a policy, then evaluate the random policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# You can reuse the \"evaluate\" function that we already apply to \n",
    "# the Frozen Lake environment, however pay attention on how to determine \n",
    "# the end of an episode (it is no more state 15). \n",
    "# Hints: you have the \"done\" information from step function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Use the value-iteration (or the policy-iteration) algorithm to calculate the optimal policy and also the optimal state-value function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# You can reuse the \"value_iteration\" function or \n",
    "# the \"policy_iteration” function that we already \n",
    "# apply to the Frozen Lake environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Calculate the performance of the obtained optimal policy using the brute force approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# You can reuse the \"evaluation\" function written before, \n",
    "# in order to evaluate the optimal policy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5  - Show the optimal policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# You can reuse the \"show_policy\" function written before, \n",
    "# in order to show the optimal policy\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "math_differential_calculus",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "8aeb84091b1f1fb8d8b9efbf1e96a552fa0144c39bfbc7f744113ad2216f701d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
