{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blackjack\n",
    "\n",
    "The game starts with the dealer having one face up and one face down card, while the player has two face up cards. All cards are drawn from an infinite deck (i.e. with replacement). The card values are:\n",
    "\n",
    "- Face cards (Jack, Queen, King) have a point value of 10\n",
    "- Aces can either count as 11 (called a \"usable ace\") or 1\n",
    "- Numerical cards (2-9) have a value equal to their number\n",
    "\n",
    "The player has the sum of cards held. The player can request additional cards (hit) until they decide to stop (stick) or exceed 21 (bust, immediate loss). After the player sticks, the dealer reveals their facedown card, and draws cards until their sum is 17 or greater. If the dealer goes bust, the player wins. If neither the player nor the dealer busts, the outcome (win, lose, draw) is decided by whose sum is closer to 21.\n",
    "\n",
    "There is two possible actions:\n",
    "\n",
    "- 0: Stick\n",
    "- 1: Hit\n",
    "\n",
    "The observation consists of a 3-tuple containing: the player’s current sum, the value of the dealer’s one showing card (1-10 where 1 is ace), and whether the player holds a usable ace (0 or 1).\n",
    "\n",
    "The player receives positive +1 rewards for winning the game, negative -1 for loosing the game and 0 reward in case of drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Import the 'Blackjack-v1' environment from Gymnasium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can get the environment from Gymnasium in the same way we got 'Frozen Lake’; \n",
    "# in order to visually plot the environment you can import it \n",
    "# using render_mode=\"rgb_array\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Create a random policy as a baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have to create a function that get in input a state and provide a random \n",
    "# action (in the range [0;1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Show the policy in action by rendering the environment several times after different decisions from the random policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse the show_policy function we implment for the lab on DP:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Write a brute-force function in order to evaluate the probability of success and the average return obtained by a policy, the evaluate the random policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can reuse the \"evaluate\" function we implment for the lab on DP, \n",
    "# however pay attention on how to calculte the success rate, you need to  \n",
    "# consider that the agent reaches the goal if it obtains a reward of 1 at   \n",
    "# the end of an episode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Notice that the state space is not a single integer, but a tuple of discrete states. In order to use the state as an index in the value function, you need to convert the tuple of states into a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert the tuple of discrete states \n",
    "# (Discrete(32), Discrete(11), Discrete(2)) into a single index, \n",
    "# you can treat the tuple as a coordinate in a 3D grid and \n",
    "# compute a unique index for each combination of values. \n",
    "# This is essentially flattening the multi-dimensional space \n",
    "# into a one-dimensional array. \n",
    "# Given a tuple of states (s1, s2, s3) where:\n",
    "# - s1 is in the range 0 to 31 (32 possible values),\n",
    "# - s2 is in the range 0 to 10 (11 possible values),\n",
    "# - s3 is in the range 0 to 1 (2 possible values),\n",
    "# You can calculate the index by assuming that s3 is the least \n",
    "# significant and s1 is the most significant:\n",
    "# index = s1 * (11 * 2) + s2 * 2 + s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Use Double Q-learning to calculate the optimal policy and the optimal state-value function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can reuse the function we apply to the Slippery Walk environment, in particular\n",
    "# select_action() to use an epsilon greedy exploration strategy, decay_schedule() to\n",
    "# calculare learning rate and epsilon values and double_q_learning() to implement the\n",
    "# algorithm. However, you need to use the state_to_index() function to convert the \n",
    "# state into an index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - Calculate the performance of the obtained optimal policy using the brute force approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can reuse the \"evaluation\" function written before, \n",
    "# in order to evaluate the optimal policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8  - Show the optimal policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can reuse the \"show_policy\" function written before, \n",
    "# in order to show the optimal policy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "math_differential_calculus",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "8aeb84091b1f1fb8d8b9efbf1e96a552fa0144c39bfbc7f744113ad2216f701d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
